{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e52f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "Notebook overview \n",
    "\n",
    "1. We extracted data from the “All of Us” Research Program with 1,295 cases (essential hypertension and co-occurring dementia, after excluding individuals with Parkinson’s disease, Vascular dementia, Frontotemporal dementia, Huntington’s disease, or Creutzfeldt-Jakob disease) and 45,752 controls (essential hypertension but without any neurodegenerative conditions).\n",
    "2. We extracted relatedness data.\n",
    "3. We extracted ancestry predictions data.\n",
    "4. We took European ancestry and removed related sample ids.\n",
    "5. We prepared the Phenotype and covariate file jointly.\n",
    "6. We ran Genome-wide association using PLINK.2.0 and 10 principle components, sex_at_birth, current age (2024-year of birth) as covariates and age filter > 60. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06504a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required python libraries\n",
    "import pandas\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query represents dataset \"EHT_Dem_remove_PD_VD_FTD_Hu_CJD\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_02537279_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (380986, 380701, 379778, 441535, 378726, 43021816, 4103534, 37117145, 372241, 4092747, 443864, 4043378, 377788, 4182210, 44782771, 37312035, 35608576, 444091, 376095, 4046090, 44782763, 4228133)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) \n",
    "            AND cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (314423, 4062811, 312648, 321638, 320456, 4217486, 314103, 4302591, 320128)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) \n",
    "            AND cb_search_person.person_id NOT IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (4064308, 4253363, 4204820, 36713737, 4126631, 4140090, 4177039, 441458, 4171569)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) \n",
    "            AND cb_search_person.person_id NOT IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (443605, 4046090, 4047747, 37018688)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) \n",
    "            AND cb_search_person.person_id NOT IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN (4043378) \n",
    "                    AND is_standard = 1 )) criteria ) \n",
    "            AND cb_search_person.person_id NOT IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN (40483103) \n",
    "                    AND is_standard = 1 )) criteria ) \n",
    "            AND cb_search_person.person_id NOT IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN (372241) \n",
    "                    AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "dataset_02537279_person_df = pandas.read_gbq(\n",
    "    dataset_02537279_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_02537279_person_df.to_csv(\"EHT_Dem_remove_PD_VD_FTD_Hu_CJD.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52420a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"EHT\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_61808986_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (312648, 320128)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "dataset_61808986_person_df = pandas.read_gbq(\n",
    "    dataset_61808986_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_61808986_person_df.to_csv(\"EHT.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a2f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the chromosomes were downloaded from All of Us Controlled Tier Dataset v7\n",
    "!gsutil -u $GOOGLE_PROJECT -m cp -r gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/acaf_threshold_v7.1/plink_bed/acaf_threshold.chr1.* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8798e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relatedness data was downloaded from All of Us Controlled Tier Dataset v7\n",
    "!gsutil -u $GOOGLE_PROJECT -m cp -r gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/aux/relatedness* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac551f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relatedness data copied into the current folder\n",
    "\n",
    "!cp relatedness/relatedness_flagged_samples.tsv rel.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a43c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relatedness data were extracted with there FID and IID\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"rel.tsv\")\n",
    "\n",
    "# Rename the column\n",
    "df.rename(columns={'sample_id': 'FID'}, inplace=True)\n",
    "\n",
    "# Copy the values from 'FID' to 'IID'\n",
    "df['IID'] = df['FID']\n",
    "\n",
    "df.to_csv(\"rel1.txt\", sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75986fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ancestry prediction data was downloaded from All of Us Controlled Tier Dataset v7\n",
    "\n",
    "!gsutil -u $GOOGLE_PROJECT -m cp gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/aux/ancestry/ancestry_preds.tsv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ancestry prediction data helped in extraction of the principal components (PC) values\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the TSV file into a DataFrame\n",
    "df = pd.read_csv('ancestry_preds.tsv', sep='\\t')\n",
    "df[\"pca_features\"] = df[\"pca_features\"].str[1:-1]\n",
    "PCs = df[\"pca_features\"].str.split(\",\", n = 16, expand = True)\n",
    "PCs = PCs.astype(float)\n",
    "pid = df[[\"research_id\"]]\n",
    "columns= [\"PC1\",\"PC2\",\"PC3\",\"PC4\",\"PC5\",\"PC6\",\"PC7\",\"PC8\",\"PC9\",\"PC10\",\"PC11\",\"PC12\",\"PC13\",\"PC14\",\"PC15\",\"PC16\"]\n",
    "PCs.columns = columns\n",
    "PCs.head(5)\n",
    "PCs_final = pd.concat([pid, PCs], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aabfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load cases (essential hypertension and co-occurring dementia, after excluding individuals with Parkinson’s disease, Vascular dementia, Frontotemporal dementia, Huntington’s disease, or Creutzfeldt-Jakob disease)\n",
    "\n",
    "dfx = pd.read_csv(\"EHT_Dem_remove_PD_FTD_VD_Hu_CJD.csv\")\n",
    "\n",
    "# Merge the dataframes\n",
    "merged_df = PCs_final.merge(dfx, left_on='research_id', right_on='person_id')\n",
    "\n",
    "# Filter rows where ancestry_pred is 'eur'\n",
    "filtered_df = df[df['ancestry_pred'] == 'eur']\n",
    "\n",
    "cases_df = merged_df.merge(filtered_df, on='research_id')\n",
    "\n",
    "# Keep only the first column\n",
    "df2 = cases_df1.iloc[:, [0]]\n",
    "\n",
    "# Step 1: Copy values from 'research_id' to 'FID'\n",
    "df2['FID'] = df2['research_id']\n",
    "\n",
    "# Step 2: Rename 'research_id' to 'IID'\n",
    "df2.rename(columns={'research_id': 'IID'}, inplace=True)\n",
    "\n",
    "# Merge the dataframes\n",
    "cases_df2 = df2.merge(cases_df1, left_on='IID', right_on='research_id')\n",
    "\n",
    "cases_df4 = cases_df2.drop(columns=['research_id'])\n",
    "\n",
    "cases_df4['Pheno']=2\n",
    "\n",
    "df1 = pd.read_csv(\"EHT_Dem_remove_PD_FTD_VD_Hu_CJD.csv\")\n",
    "\n",
    "# Extract the 'person_id' column\n",
    "dff1 = df1['person_id']\n",
    "\n",
    "print(\"\\nExtracted 'person_id' Column:\")\n",
    "print(dff1)\n",
    "\n",
    "dff1.columns = ['person_id']\n",
    "\n",
    "# Extracting 'person id' and 'gender' columns\n",
    "cases_df = df1[['person_id', 'gender']]\n",
    "\n",
    "# Merge to find common rows\n",
    "matching_rows = control_df.merge(cases_df, on=list(control_df.columns))\n",
    "\n",
    "# Remove matching rows from df\n",
    "df_filtered = df[~df.isin(matching_rows.to_dict(orient='list')).all(axis=1)]\n",
    "\n",
    "# Adding 'Pheno' column with value 1\n",
    "cases_df['Pheno'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cab5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load controls (essential hypertension but without any neurodegenerative conditions)\n",
    "\n",
    "df2 = pd.read_csv(\"EHT.csv\")\n",
    "\n",
    "# Extract the 'person_id' column\n",
    "dff2 = df2['person_id']\n",
    "\n",
    "print(\"\\nExtracted 'person_id' Column:\")\n",
    "print(dff2)\n",
    "\n",
    "dff2.columns = ['person_id']\n",
    "\n",
    "# Extracting 'person id' and 'gender' columns\n",
    "control_df = df2[['person_id', 'gender']]\n",
    "\n",
    "# Adding 'Pheno' column with value 1\n",
    "control_df['Pheno'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc2aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating DataFrames along rows\n",
    "concatenated_df = pd.concat([cases_df, control_df], axis=0)\n",
    "\n",
    "concatenated_df['Pheno'].value_counts()\n",
    "\n",
    "# Mapping gender values to numeric codes\n",
    "gender_map = {'Male': 1, 'Female': 2}\n",
    "concatenated_df['gender'] = concatenated_df['gender'].map(gender_map)\n",
    "\n",
    "# Dropping rows with NaN values in the gender column (invalid gender values)\n",
    "concatenated_df.dropna(subset=['gender'], inplace=True)\n",
    "\n",
    "# Converting gender column to integer type\n",
    "concatenated_df['gender'] = concatenated_df['gender'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501e2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = pd.read_csv(\"EHT.csv\")\n",
    "\n",
    "controls1 = controls['person_id']\n",
    "\n",
    "controls_df1 = pd.DataFrame(controls, columns=['person_id'])\n",
    "\n",
    "# Merge the dataframes\n",
    "controls_df2 = df.merge(controls_df1, left_on='research_id', right_on='person_id’)\n",
    "\n",
    "# Filter rows where ancestry_pred is 'eur'\n",
    "controls_df4 = controls_df2[controls_df2['ancestry_pred'] == 'eur']\n",
    "\n",
    "# Merge the dataframes\n",
    "controls_df5 = controls_df4.merge(PCs_final, on='research_id’)\n",
    "\n",
    "controls_df7 = controls_df5.drop(columns=['ancestry_pred', 'probabilities', 'pca_features', 'ancestry_pred_other','person_id','PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16'])\n",
    "\n",
    "# Step 1: Copy values from 'research_id' to 'FID'\n",
    "controls_df7['FID'] = controls_df7['research_id']\n",
    "\n",
    "# Step 2: Rename 'research_id' to 'IID'\n",
    "controls_df7.rename(columns={'research_id': 'IID'}, inplace=True)\n",
    "\n",
    "controls_df7['Pheno']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac301931",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = pd.read_csv(\"EHT_Dem_remove_PD_FTD_VD_Hu_CJD.csv\")\n",
    "\n",
    "cases1 = cases['person_id']\n",
    "\n",
    "cases1.head()\n",
    "\n",
    "cases_df1 = pd.DataFrame(cases1, columns=['person_id'])\n",
    "\n",
    "# Merge the dataframes\n",
    "cases_df2 = df.merge(cases_df1, left_on='research_id', right_on='person_id')\n",
    "\n",
    "# Only European ancestry was choosen from the samples\n",
    "\n",
    "# Filter rows where ancestry_pred is 'eur'\n",
    "cases_df4 = cases_df2[cases_df2['ancestry_pred'] == 'eur']\n",
    "\n",
    "# Merge the dataframes\n",
    "cases_df5 = cases_df4.merge(PCs_final, on='research_id')\n",
    "\n",
    "cases_df7 = cases_df5.drop(columns=['ancestry_pred', 'probabilities', 'pca_features', 'ancestry_pred_other','person_id','PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16'])\n",
    "\n",
    "cases_df7['Pheno']=2\n",
    "\n",
    "# Step 1: Copy values from 'research_id' to 'FID'\n",
    "cases_df7['FID'] = cases_df7['research_id']\n",
    "\n",
    "# Step 2: Rename 'research_id' to 'IID'\n",
    "cases_df7.rename(columns={'research_id': 'IID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955ff89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate DataFrames\n",
    "concatenated_df1 = pd.concat([cases_df7, controls_df7], ignore_index=True)\n",
    "\n",
    "# Swapping the FID and IID columns\n",
    "concatenated_df2 = concatenated_df1[['FID', 'IID', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'Pheno']]\n",
    "\n",
    "# Merge the dataframes on the matching columns\n",
    "merged_df = pd.merge(concatenated_df, concatenated_df1, left_on='person_id', right_on='IID')\n",
    "\n",
    "# Drop the 'person_id' and 'pheno_x' columns\n",
    "result_df = merged_df.drop(columns=['person_id', 'Pheno_x’])\n",
    "\n",
    "# Rename 'pheno_x' to 'pheno'\n",
    "result_df1 = result_df.rename(columns={'Pheno_y': 'Pheno'})\n",
    "\n",
    "# Get the list of columns\n",
    "columns = ['gender', 'FID', 'IID', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'Pheno']\n",
    "\n",
    "# Move the first column to the end\n",
    "columns.append(columns.pop(0))\n",
    "\n",
    "# Reorder the dataframe\n",
    "df_reordered = result_df1[columns]\n",
    "\n",
    "final = df_reordered.drop_duplicates()\n",
    "\n",
    "# Drop duplicates based on the IID column\n",
    "final = final.drop_duplicates(subset='IID')\n",
    "\n",
    "# Count occurrences of each value in the 'Pheno' column\n",
    "pheno_counts = final['Pheno'].value_counts()\n",
    "\n",
    "# Get the counts for specific values\n",
    "count_1 = pheno_counts.get(1, 0)\n",
    "count_2 = pheno_counts.get(2, 0)\n",
    "\n",
    "print(f\"Number of 1s in 'Pheno': {count_1}\")\n",
    "print(f\"Number of 2s in 'Pheno': {count_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1c5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phenotype file containing the phenotype and covariates were jointly made\n",
    "\n",
    "final.to_csv(\"Pheno_HT_Dem_Vs_HT_remove_PD_VD_FTD_Hu_CJD.txt\", sep = '\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a88154",
   "metadata": {},
   "source": [
    "# Relatedness was removed from the samples\n",
    "\n",
    "!plink2 --bfile acaf_threshold.chr2 --remove rel1.txt --make-bed --out acaf_threshold.chr2.rel.removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b1646",
   "metadata": {},
   "source": [
    "# Genome-wide association analysis was done\n",
    "\n",
    "%%bash\n",
    "plink2 --bfile acaf_threshold.chr2.rel.removed --snp chr2:36408804:T:C --geno 0.05 \\\n",
    "        --maf 0.05 \\\n",
    "      --pheno Pheno_HT_Dem_Vs_HT_remove_PD_VD_FTD_Hu_CJD.txt \\\n",
    "      --pheno-name Pheno \\\n",
    "      --covar Pheno_HT_Dem_Vs_HT_remove_PD_VD_FTD_Hu_CJD.txt \\\n",
    "      --covar-name PC1,PC2,PC3,PC4,PC5,gender \\\n",
    "      --keep Pheno_HT_Dem_Vs_HT_remove_PD_VD_FTD_Hu_CJD.txt \\\n",
    "      --allow-no-sex \\\n",
    "      --glm hide-covar no-x-sex cols=+beta,+a1freq,+a1freqcc,+a1count,+totallele,+a1countcc,+totallelecc,+err \\\n",
    "      --out gwas_2_wgs_remove_PD_VD_FTD_Hu_CJD"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
